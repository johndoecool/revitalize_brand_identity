# =============================================================================
# Data Collection Service Pipeline for Revitalize Brand Identity
# =============================================================================
# This pipeline builds, tests, and deploys the Data Collection microservice
# Triggers on changes to data-collection/ directory
# =============================================================================

trigger:
  branches:
    include:
    - master
  paths:
    include:
    - data-collection/*
    - .azure-pipelines/data-collection-pipeline.yml

pr: none

variables:
- group: Azure-Config
- group: API-Keys
- group: Storage-Config
- group: Container-Apps
- name: serviceConnection
  value: 'Azure-RevitalizeBrandIdentity'
- name: imageName
  value: '$(ACR_NAME).azurecr.io/data-collection'
- name: imageTag
  value: '$(Build.BuildNumber)'
- name: workingDirectory
  value: 'data-collection'

stages:
- stage: Build
  displayName: 'Build and Test'
  jobs:
  - job: BuildAndTest
    displayName: 'Build and Test Data Collection Service'
    pool:
      vmImage: 'ubuntu-latest'
    
    steps:
    - checkout: self
      displayName: 'Checkout Repository'
    
    - task: UsePythonVersion@0
      displayName: 'Set Python Version'
      inputs:
        versionSpec: '3.9'
        addToPath: true
    
    - script: |
        cd $(workingDirectory)
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install flake8 black pytest-cov
      displayName: 'Install Dependencies'
    
    - script: |
        cd $(workingDirectory)
        echo "Running code formatting check with black..."
        black --check --diff src/ || exit 0  # Don't fail build on formatting
        echo "Running linting with flake8..."
        flake8 src/ --max-line-length=100 --exclude=__pycache__ || exit 0  # Don't fail build on linting
      displayName: 'Code Quality Checks'
    
    - script: |
        cd $(workingDirectory)
        echo "Running unit tests with coverage..."
        # Skip selenium-based tests in CI for now
        python -m pytest tests/unit/ -v --cov=src --cov-report=xml --cov-report=html --cov-fail-under=50 -k "not selenium"
      displayName: 'Run Tests with Coverage'
    
    - task: PublishTestResults@2
      condition: succeededOrFailed()
      inputs:
        testResultsFiles: '$(workingDirectory)/junit.xml'
        testRunTitle: 'Data Collection Service Tests'
        failTaskOnFailedTests: true
    
    - task: PublishCodeCoverageResults@1
      condition: succeededOrFailed()
      inputs:
        codeCoverageTool: 'Cobertura'
        summaryFileLocation: '$(workingDirectory)/coverage.xml'
        reportDirectory: '$(workingDirectory)/htmlcov'
    
    - task: Docker@2
      displayName: 'Build Docker Image'
      inputs:
        containerRegistry: $(serviceConnection)
        repository: 'data-collection'
        command: 'build'
        Dockerfile: '$(workingDirectory)/Dockerfile'
        buildContext: '$(workingDirectory)'
        tags: |
          $(imageTag)
          latest
    
    - task: Docker@2
      displayName: 'Push Docker Image'
      inputs:
        containerRegistry: $(serviceConnection)
        repository: 'data-collection'
        command: 'push'
        tags: |
          $(imageTag)
          latest

- stage: Deploy
  displayName: 'Deploy to Azure Container Apps'
  dependsOn: Build
  condition: succeeded()
  jobs:
  - deployment: DeployDataCollection
    displayName: 'Deploy Data Collection Service'
    pool:
      vmImage: 'ubuntu-latest'
    environment: 'Production'
    strategy:
      runOnce:
        deploy:
          steps:
          - task: AzureCLI@2
            displayName: 'Deploy to Container Apps'
            inputs:
              azureSubscription: $(serviceConnection)
              scriptType: 'bash'
              scriptLocation: 'inlineScript'
              inlineScript: |
                echo "Deploying Data Collection Service to Container Apps..."
                
                # Check if container app exists
                if az containerapp show --name $(DATA_COLLECTION_SERVICE_NAME) --resource-group $(RESOURCE_GROUP) >/dev/null 2>&1; then
                  echo "Updating existing Container App: $(DATA_COLLECTION_SERVICE_NAME)"
                  az containerapp update \
                    --name $(DATA_COLLECTION_SERVICE_NAME) \
                    --resource-group $(RESOURCE_GROUP) \
                    --image $(imageName):$(imageTag) \
                    --set-env-vars PYTHONPATH=/app PYTHONUNBUFFERED=1 \
                    --secrets openai-api-key=$(OPENAI_API_KEY) together-api-key=$(TOGETHER_API_KEY) storage-key=$(STORAGE_ACCOUNT_KEY) \
                    --env-vars OPENAI_API_KEY=secretref:openai-api-key TOGETHER_API_KEY=secretref:together-api-key STORAGE_ACCOUNT_NAME=$(STORAGE_ACCOUNT_NAME) STORAGE_ACCOUNT_KEY=secretref:storage-key FILE_SHARE_NAME=$(FILE_SHARE_NAME)
                else
                  echo "Creating new Container App: $(DATA_COLLECTION_SERVICE_NAME)"
                  az containerapp create \
                    --name $(DATA_COLLECTION_SERVICE_NAME) \
                    --resource-group $(RESOURCE_GROUP) \
                    --environment $(CONTAINER_APPS_ENV) \
                    --image $(imageName):$(imageTag) \
                    --target-port $(DATA_COLLECTION_PORT) \
                    --ingress external \
                    --min-replicas 1 \
                    --max-replicas 3 \
                    --cpu 1.0 \
                    --memory 2Gi \
                    --secrets openai-api-key=$(OPENAI_API_KEY) together-api-key=$(TOGETHER_API_KEY) storage-key=$(STORAGE_ACCOUNT_KEY) \
                    --env-vars PYTHONPATH=/app PYTHONUNBUFFERED=1 OPENAI_API_KEY=secretref:openai-api-key TOGETHER_API_KEY=secretref:together-api-key STORAGE_ACCOUNT_NAME=$(STORAGE_ACCOUNT_NAME) STORAGE_ACCOUNT_KEY=secretref:storage-key FILE_SHARE_NAME=$(FILE_SHARE_NAME)
                fi
                
                echo "Deployment completed successfully!"
          
          - task: AzureCLI@2
            displayName: 'Get Service URL'
            inputs:
              azureSubscription: $(serviceConnection)
              scriptType: 'bash'
              scriptLocation: 'inlineScript'
              inlineScript: |
                echo "Getting Data Collection Service URL..."
                SERVICE_URL=$(az containerapp show --name $(DATA_COLLECTION_SERVICE_NAME) --resource-group $(RESOURCE_GROUP) --query "properties.configuration.ingress.fqdn" -o tsv)
                echo "Data Collection Service is available at: https://$SERVICE_URL"
                echo "Health check: https://$SERVICE_URL/health"
                echo "API docs: https://$SERVICE_URL/docs"
                
                # Set output variable for other stages/jobs
                echo "##vso[task.setvariable variable=dataCollectionUrl;isOutput=true]https://$SERVICE_URL"
          
          - task: AzureCLI@2
            displayName: 'Health Check'
            inputs:
              azureSubscription: $(serviceConnection)
              scriptType: 'bash'
              scriptLocation: 'inlineScript'
              inlineScript: |
                echo "Performing health check..."
                SERVICE_URL=$(az containerapp show --name $(DATA_COLLECTION_SERVICE_NAME) --resource-group $(RESOURCE_GROUP) --query "properties.configuration.ingress.fqdn" -o tsv)
                
                # Wait for service to be ready
                for i in {1..10}; do
                  echo "Health check attempt $i/10..."
                  if curl -f "https://$SERVICE_URL/health" >/dev/null 2>&1; then
                    echo "✅ Data Collection Service is healthy and responding!"
                    exit 0
                  fi
                  echo "Service not ready yet, waiting 30 seconds..."
                  sleep 30
                done
                
                echo "⚠️ Health check timed out, but deployment may still be in progress"
                echo "Check the service status in Azure Portal"